{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#0b486b\">SIT 112 - Data Science Concepts</span>\n",
    "\n",
    "---\n",
    "Lecturer: Truyen Tran | truyen.tran@deakin.edu.au<br />\n",
    "\n",
    "School of Information Technology, <br />\n",
    "Deakin University, VIC 3216, Australia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#0b486b\">Practical Session 10: Naive Bayes Classifier</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#0b486b\">Naive Bayes Classifier</span> \n",
    "\n",
    "\n",
    "Naive Bayes is one of the most practical classification machine learning algorithms. \n",
    "\n",
    "* fast\n",
    "* good performance\n",
    "* simple yet very effective\n",
    "* robust to irrelative features\n",
    "\n",
    "So why is it called naive?\n",
    "\n",
    "Because it does not consider the dependency between features and assume all features are independent of each other which is not the case in reality. This is a naive assumption, hence the name.\n",
    "\n",
    "The accuracy is very good although this naive assumption. A famous example of NB usage is spam filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Example1\n",
    "\n",
    "We assume we have collected the below data for the past 5 days. Based on this data, can we predict if our subject will play in a setting like:\n",
    "\n",
    "    outlook  = overcast\n",
    "    temp     = hot\n",
    "    humidity = normal\n",
    "    windy    = no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- <img src=\"nb_data.png\" width=\"800\"> -->\n",
    "<img src=\"nb_data.png\" width=\"800\">\n",
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to find a representation for our data. We can construct a dictionary to convert stings into numbers and then save them in a dataframe. \n",
    "\n",
    "    outlook: sunny=0, overcast=1, rainy=2\n",
    "    temp: hot=0, mild=1, cool=2\n",
    "    humidity: normal=0, high=1\n",
    "    wind: no=0, yes=1\n",
    "    play: np=0, yes=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    'outlook': [0, 1, 2, 0, 1],\n",
    "    'temp'   : [0, 1, 2, 1, 0],\n",
    "    'humid'  : [0, 0, 1, 0, 1],\n",
    "    'wind'   : [0, 0, 1, 1, 0],\n",
    "    'play'   : [1, 1, 0, 0, 0,]    \n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use Bayes rule to construct a Naive Bayes classifier. We can write:\n",
    "\n",
    "$$Pr\\left(p|o,t,h,w\\right)\\propto Pr\\left(p\\right)Pr(o|p)Pr(t|p)Pr(h|p)Pr(w|p)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate $Pr(p)$ we use marginal probablity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def marginal_prob(df, column):\n",
    "    '''\n",
    "    Compute the marignal probability for values in a column\n",
    "    '''\n",
    "    # an array contain pairs of (value, count)\n",
    "    vals_counts = [(val, (df[column] == val).sum()) for val in set(df[column])]\n",
    "    total_count = sum([count for val, count in vals_counts])\n",
    "    \n",
    "    # an array contain pairs of (value, probability)\n",
    "    vals_probs = [(val, count/total_count) for val, count in vals_counts]\n",
    "    # a dictionary in which keys are val and values are the corresponding probabilities\n",
    "    return dict(vals_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate probability of a feature given the class (play) we use conditinoal probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conditional_prob(df, feature, c, val):\n",
    "    # c is the class (0 or 1)\n",
    "    df2 = df[df[c] == val][feature]\n",
    "    vals_counts = [[val, (df2 == val).sum() + 1e-8] for val in set(df[feature])]\n",
    "    total_count = sum([count for val, count in vals_counts])\n",
    "    \n",
    "    vals_probs = [(val, count/total_count) for val, count in vals_counts]\n",
    "    return dict(vals_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use Bayes rule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability of not playing: 0.0689655189536266\n",
      "probability of playing    : 0.9310344810463733\n"
     ]
    }
   ],
   "source": [
    "o = 1\n",
    "t = 0\n",
    "h = 0\n",
    "w = 0\n",
    "\n",
    "c = 0\n",
    "p0 = marginal_prob(df, 'play')[c] * conditional_prob(df, 'outlook', 'play', c)[o] * conditional_prob(df, 'temp', 'play', c)[t] \\\n",
    "* conditional_prob(df, 'humid', 'play', c)[h] * conditional_prob(df, 'wind', 'play', c)[w]\n",
    "\n",
    "c = 1\n",
    "p1 = marginal_prob(df, 'play')[c] * conditional_prob(df, 'outlook', 'play', c)[o] * conditional_prob(df, 'temp', 'play', c)[t] \\\n",
    "* conditional_prob(df, 'humid', 'play', c)[h] * conditional_prob(df, 'wind', 'play', c)[w]\n",
    "\n",
    "# normalizing\n",
    "p_sum = p0 + p1\n",
    "p0 /= p_sum\n",
    "p1 /= p_sum\n",
    "\n",
    "print(\"probability of not playing: {}\".format(p0))\n",
    "print(\"probability of playing    : {}\".format(p1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Example 2\n",
    "\n",
    "Suppose we have documents below as our training set. \n",
    "\n",
    "    d1: Chinese Beijing Chinese , class = C\n",
    "    d2: Chinese Chinese Shanghai, class = C\n",
    "    d3: Chinese Macao           , class = C\n",
    "    d4: Tokyo Japan Chinese     , class = J\n",
    "\n",
    "\n",
    "**Exercise:** Train a NB classifier and predict if `d5` belongs to class C or J.\n",
    "\n",
    "    d5: Chinese Chinese Chinese Tokyo Japan, class = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create data frame\n",
    "# class 0 is C and class 1 is J\n",
    "data = {\n",
    "    'Chinese' : [2, 2, 1, 1],\n",
    "    'Beijing' : [1, 0, 0, 0],\n",
    "    'Shanghai': [0, 1, 0, 0],\n",
    "    'Macao'   : [0, 0, 1, 0],\n",
    "    'Tokyo'   : [0, 0, 0, 1],\n",
    "    'Japan'   : [0, 0, 0, 1],\n",
    "    'class'   : [0, 0, 0, 1]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.99999999666666672, 1: 3.3333333111111114e-09}\n",
      "probability of C: 6.584362464800417e-10\n",
      "probability of J: 0.9999999993415637\n"
     ]
    }
   ],
   "source": [
    "# New data point d5\n",
    "# Can you think of any strategy to make the code shorter and more efficient?\n",
    "chinese  = 2\n",
    "beijing  = 0\n",
    "shanghai = 0\n",
    "macao    = 0\n",
    "tokyo    = 1\n",
    "japan    = 1\n",
    "\n",
    "c = 0\n",
    "print(conditional_prob(df, 'Tokyo', 'class', c))\n",
    "p0 = marginal_prob(df, 'class')[c] \\\n",
    "    * conditional_prob(df, 'Chinese', 'class', c)[chinese] \\\n",
    "    * conditional_prob(df, 'Beijing', 'class', c)[beijing] \\\n",
    "    * conditional_prob(df, 'Shanghai', 'class', c)[shanghai] \\\n",
    "    * conditional_prob(df, 'Macao', 'class', c)[macao] \\\n",
    "    * conditional_prob(df, 'Tokyo', 'class', c)[tokyo] \\\n",
    "    * conditional_prob(df, 'Japan', 'class', c)[japan] \\\n",
    "\n",
    "c = 1\n",
    "p1 = marginal_prob(df, 'class')[c] \\\n",
    "    * conditional_prob(df, 'Chinese', 'class', c)[chinese] \\\n",
    "    * conditional_prob(df, 'Beijing', 'class', c)[beijing] \\\n",
    "    * conditional_prob(df, 'Shanghai', 'class', c)[shanghai] \\\n",
    "    * conditional_prob(df, 'Macao', 'class', c)[macao] \\\n",
    "    * conditional_prob(df, 'Tokyo', 'class', c)[tokyo] \\\n",
    "    * conditional_prob(df, 'Japan', 'class', c)[japan] \\\n",
    "    \n",
    "# normalizing\n",
    "p_sum = p0 + p1\n",
    "p0 /= p_sum\n",
    "p1 /= p_sum\n",
    "\n",
    "print(\"probability of C: {}\".format(p0))\n",
    "print(\"probability of J: {}\".format(p1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
